audit {
  active = true
  active = ${?SL_AUDIT_ACTIVE}
  auditTimeout = -1
  auditTimeout = ${?SL_LOCK_AUDIT_TIMEOUT}
  sql = "select {{ cols }}"
  maxErrors = 100
  # detailedLoadAudit = "false" / SL_DETAILED_LOAD_AUDIT: create individual entry for each ingested file instead of a global one. Default: false
  detailedLoadAudit = false
  detailedLoadAudit = ${?SL_DETAILED_LOAD_AUDIT}

  database = ${?SL_AUDIT_DATABASE}
  domain = "audit"
  domain = ${?SL_AUDIT_DOMAIN}

  // used for logging only
  domainExpectations = "expectations"
  domainExpectations = ${?SL_AUDIT_EXPECTATIONS_DOMAIN}
  domainExpectations = ${?SL_AUDIT_DOMAIN}

  // used for logging only
  domainRejected = "rejected"
  domainRejected = ${?SL_AUDIT_REJECTED_DOMAIN}
  domainRejected = ${?SL_AUDIT_DOMAIN}

  # FS Options
  path = ${datasets}"/audit"
  path = ${?SL_AUDIT_PATH}

  sink {
    #connectionRef = "audit" // serves as dataset name for BigQuery or Elasticsearch index name or JDBC Schema
    connectionRef = ${?SL_CONNECTION_REF}
    connectionRef = ${?SL_AUDIT_SINK_CONNECTION_REF}

    ## BigQuery options
    # location = "europe-west1"
    # timestamp = "_PARTITIONTIME"
    # clustering = "???"
    # days = 7
    # require-partition-filter = false

    options = {
      allowFieldAddition: "true"
      allowFieldAddition: ${?SL_AUDIT_ALLOW_FIELD_ADDITION}
      allowFieldRelaxation: "true"
      allowFieldRelaxation: ${?SL_AUDIT_ALLOW_FIELD_RELAXATION}
    }



    # Jdbc options
    partitions = 1
    partitions = ${?SL_AUDIT_SINK_PARTITIONS}
    batchSize = 1000
    batchSize = ${?SL_AUDIT_SINK_BATCH_SIZE}
  }
}

