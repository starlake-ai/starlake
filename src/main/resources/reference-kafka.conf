kafka {
  comet-offsets-mode = "STREAM"
  custom-deserializers {
   #"deserialize": "io.confluent.kafka.serializers.KafkaAvroDeserializer"
  }
  server-options {
    "bootstrap.servers": "localhost:9092"
  }
  topics {
    logs {
      topic-name: logs
      max-read = 0
      fields = ["key as STRING", "value as STRING", "topic as STRING", "partition as INT", "offset as LONG", "timestamp as TIMESTAMP", "timestampType as INT"]
      write-format = "parquet"
      create-options {
        "cleanup.policy": "compact"
      }
      access-options {
        "kafka.bootstrap.servers": "localhost:9092"
        "bootstrap.servers": "localhost:9092"
        "key.deserializer": "org.apache.kafka.common.serialization.StringDeserializer",
        "value.deserializer": "org.apache.kafka.common.serialization.StringDeserializer"
        "subscribe": "logs"
      }
    },
    comet_offsets {
      topic-name: comet_offsets
      max-read = 0
      partitions = 1
      replication-factor = 1
      write-format = "parquet"
      create-potions {
        "cleanup.policy": "compact"
      }
      access-options {
        "kafka.bootstrap.servers": "localhost:9092"
        "auto.offset.reset": "earliest"
        "auto.commit.enable": "false"
        "consumer.timeout.ms": "10"
        "bootstrap.servers": "localhost:9092"
        "key.deserializer": "org.apache.kafka.common.serialization.StringDeserializer",
        "value.deserializer": "org.apache.kafka.common.serialization.StringDeserializer"
        "subscribe": "comet_offsets"
      }
    }
  }
}
