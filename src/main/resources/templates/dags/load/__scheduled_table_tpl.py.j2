{% include 'templates/dags/__common__.py.j2' %}
from ai.starlake.job import StarlakePreLoadStrategy, StarlakeJobFactory

import os

import sys

sl_job = StarlakeJobFactory.create_job(
    filename=os.path.basename(__file__), 
    module_name=f"{__name__}", 
    orchestrator=orchestrator,
    execution_environment=execution_environment,
    options=options
)

from ai.starlake.common import sanitize_id
from ai.starlake.orchestration import StarlakeSchedule, StarlakeDomain, StarlakeTable, OrchestrationFactory

schedules= [{% for schedule in context.schedules %}
    StarlakeSchedule(
        name='{{ schedule.schedule }}', 
        cron={% if schedule.cron is not none %}'{{ schedule.cron }}'{% else %}None{% endif %}, 
        domains=[{% for domain in schedule.domains %}
            StarlakeDomain(
                name='{{ domain.final_name }}', 
                final_name='{{ domain.final_name }}', 
                tables=[{% for table in domain.tables %}
                    StarlakeTable(
                        name='{{ table.final_name }}', 
                        final_name='{{ table.final_name }}'
                    ){% if not loop.last  %},{% endif %}{% endfor %}
                ]
            ){% if not loop.last  %},{% endif %}{% endfor %}
    ]){% if not loop.last  %},{% endif %}{% endfor %}
]

with OrchestrationFactory.create_orchestration(job=sl_job) as orchestration:

    def generate_pipeline(schedule: StarlakeSchedule):
        if len(schedules) == 1:
            # if only one schedule, do not use the schedule name within the pipeline name
            schedule.name = None
        # generate the load pipeline
        with orchestration.sl_create_pipeline(
            schedule=schedule,
        ) as pipeline:

            schedule       = pipeline.schedule
            if schedule.name:
                schedule_name = sanitize_id(schedule.name)
            else:
                schedule_name = None

            start = pipeline.start_task()
            if not start:
                raise Exception("Start task not defined")

            pre_tasks = pipeline.pre_tasks()

            if pre_tasks:
                start >> pre_tasks

            def generate_load_domain(domain: StarlakeDomain):

                if schedule_name:
                    name = f"{domain.name}_{schedule_name}"
                else:
                    name = domain.name

                with orchestration.sl_create_task_group(group_id=sanitize_id(name), pipeline=pipeline) as ld:

                    pre_load_strategy=pipeline.pre_load_strategy

                    def pre_load(pre_load_strategy: StarlakePreLoadStrategy):
                        if pre_load_strategy != StarlakePreLoadStrategy.NONE:
                            with orchestration.sl_create_task_group(group_id=sanitize_id(f'pre_load_{name}'), pipeline=pipeline) as pre_load_tasks:
                                pre_load = pipeline.sl_pre_load(
                                        domain=domain.name, 
                                        tables=set([table.name for table in domain.tables]), 
                                    )
                                skip_or_start = pipeline.skip_or_start(
                                    task_id=f'skip_or_start_loading_{name}', 
                                    upstream_task=pre_load
                                )
                                if pre_load_strategy == StarlakePreLoadStrategy.IMPORTED:
                                    sl_import = pipeline.sl_import(
                                            task_id=f"import_{name}",
                                            domain=domain.name, 
                                            tables=set([table.name for table in domain.tables]), 
                                        )
                                else:
                                    sl_import = None

                                if skip_or_start:
                                    pre_load >> skip_or_start
                                    if sl_import:
                                        skip_or_start >> sl_import
                                elif sl_import:
                                    pre_load >> sl_import

                            return pre_load_tasks
                        else:
                            return None

                    pld = pre_load(pre_load_strategy)                              

                    def load_domain_tables():
                        with orchestration.sl_create_task_group(group_id=sanitize_id(f'load_{name}'), pipeline=pipeline) as load_domain_tables:
                            for table in domain.tables:
                                pipeline.sl_load(
                                    task_id=sanitize_id(f'load_{domain.name}_{table.name}'), 
                                    domain=domain.name, 
                                    table=table.name,
                                )

                        return load_domain_tables

                    ld_tables=load_domain_tables()

                    if pld:
                        pld >> ld_tables

                return ld

            load_domains = [generate_load_domain(domain) for domain in schedule.domains]

            end = pipeline.end_task()

            if pre_tasks:
                start >> pre_tasks >> load_domains
            else:
                start >> load_domains

            end << load_domains

            post_tasks = pipeline.post_tasks()
        
            if post_tasks:
                all_done = pipeline.sl_dummy_op(task_id="all_done")
                all_done << load_domains
                all_done >> post_tasks >> end

        return pipeline

    pipelines = [generate_pipeline(schedule) for schedule in schedules]
