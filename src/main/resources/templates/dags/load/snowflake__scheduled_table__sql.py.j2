# This template executes individual sql jobs and requires the following dag generation options set:
#
# - stage_location: the location of the stage in snowflake where store procedures are located [REQUIRED]
# - warehouse(COMPUTE_WH): the warehouse to use for the DAG [OPTIONAL], default to COMPUTE_WH
# - timezone(UTC): the timezone to use for the schedule [OPTIONAL], default to UTC
# - packages(croniter,python-dateutil,snowflake-snowpark-python): a list of packages to install before running the task [OPTIONAL], default to croniter,python-dateutil,snowflake-snowpark-python
# - sl_incoming_file_stage: the stage to use for incoming files [REQUIRED]
# - sl_env_var: starlake variables specified as a map in json format - at least the root project path SL_ROOT should be specified [OPTIONAL]
# - retries(1): the number of retries to attempt before failing the task [OPTIONAL]
# - retry_delay(300): the delay between retries in seconds [OPTIONAL]
#
{% include 'templates/dags/__starlake_snowflake_orchestrator.py' %}
{% include 'templates/dags/__starlake_sql_execution.py' %}
json_context = '''{{ pyjson }}'''
{% include 'templates/dags/__common__.py.j2' %}
from ai.starlake.job import StarlakePreLoadStrategy, StarlakeJobFactory

import os

import sys

sl_job = StarlakeJobFactory.create_job(
    filename=os.path.basename(__file__), 
    module_name=f"{__name__}", 
    orchestrator=orchestrator,
    execution_environment=execution_environment,
    options=options
)

from ai.starlake.common import sanitize_id
from ai.starlake.orchestration import StarlakeSchedule, StarlakeDomain, StarlakeTable, OrchestrationFactory

schedules= [{% for schedule in context.schedules %}
    StarlakeSchedule(
        name='{{ schedule.schedule }}', 
        cron={% if schedule.cron is not none %}'{{ schedule.cron }}'{% else %}None{% endif %}, 
        domains=[{% for domain in schedule.domains %}
            StarlakeDomain(
                name='{{ domain.final_name }}', 
                final_name='{{ domain.final_name }}', 
                tables=[{% for table in domain.tables %}
                    StarlakeTable(
                        name='{{ table.final_name }}', 
                        final_name='{{ table.final_name }}'
                    ){% if not loop.last  %},{% endif %}{% endfor %}
                ]
            ){% if not loop.last  %},{% endif %}{% endfor %}
    ]){% if not loop.last  %},{% endif %}{% endfor %}
]

with OrchestrationFactory.create_orchestration(job=sl_job) as orchestration:

    def generate_pipeline(schedule: StarlakeSchedule):
        if len(schedules) == 1:
            # if only one schedule, do not use the schedule name within the pipeline name
            schedule.name = None
        # generate the load pipeline
        with orchestration.sl_create_pipeline(
            schedule=schedule,
        ) as pipeline:

            schedule       = pipeline.schedule
            if schedule.name:
                schedule_name = sanitize_id(schedule.name)
            else:
                schedule_name = None

            start = pipeline.start_task()
            if not start:
                raise Exception("Start task not defined")

            pre_tasks = pipeline.pre_tasks()

            if pre_tasks:
                start >> pre_tasks

            end = pipeline.end_task()

            post_tasks = pipeline.post_tasks()
        
            if post_tasks:
                end << post_tasks

            pre_load_strategy: StarlakePreLoadStrategy = pipeline.pre_load_strategy

            def generate_load_domain(domain: StarlakeDomain):

                if schedule_name:
                    name = f"{domain.name}_{schedule_name}"
                else:
                    name = domain.name

                def pre_load_domain():
                    if pre_load_strategy != StarlakePreLoadStrategy.NONE:
                        pre_load = pipeline.sl_pre_load(
                                domain=domain.name, 
                                tables=set([table.name for table in domain.tables]), 
                            )
                        skip_or_start = pipeline.skip_or_start(
                            task_id=f'skip_or_start_loading_{name}', 
                            upstream_task=pre_load
                        )
                        if pre_load_strategy == StarlakePreLoadStrategy.IMPORTED:
                            sl_import = pipeline.sl_import(
                                    task_id=f"import_{name}",
                                    domain=domain.name, 
                                    tables=set([table.name for table in domain.tables]), 
                                )
                        else:
                            sl_import = None

                        if skip_or_start:
                            pre_load >> skip_or_start
                            if sl_import:
                                skip_or_start >> sl_import
                        elif sl_import:
                            pre_load >> sl_import
                    else:
                        None

                pld = pre_load_domain()
 
                def load_domain_tables():
                    domain_tables = []
                    for table in domain.tables:
                        domain_table = pipeline.sl_load(
                            task_id=sanitize_id(f'load_{domain.name}_{table.name}'), 
                            domain=domain.name, 
                            table=table.name,
                        )
                        domain_tables.append(domain_table)
                    return domain_tables
                
                ld = load_domain_tables()

                if pld:
                    pld >> ld
                elif pre_tasks:
                    pre_tasks >> ld
                else:
                    start >> ld

                if post_tasks:
                    post_tasks << ld
                else:
                    end << ld

            for domain in schedule.domains:
                generate_load_domain(domain)

        return pipeline

    pipelines = [generate_pipeline(schedule) for schedule in schedules]
