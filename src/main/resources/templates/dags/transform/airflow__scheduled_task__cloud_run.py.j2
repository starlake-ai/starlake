# This template executes individual cloud run jobs and requires the following dag generation options set:
#
# - cloud_run_project_id: the project id where the job is located (if not set, the project id of the composer environment will be used) [OPTIONAL]
# - cloud_run_job_region(europe-west1): the region where the job is located (if not set, europe-west1 will be used) [OPTIONAL]
# - cloud_run_job_name: the name of the job to execute [REQUIRED]
# - cloud_run_service_account: the service account to use for cloud run (if not set, the default service account will be used) [OPTIONAL]
# - cloud_run_async(True): whether to run the job asynchronously or not [OPTIONAL]
# - cloud_run_async_poke_interval(30): the interval in seconds to check the job status [OPTIONAL]
# - retry_on_failure(False): whether to retry the job on failure [OPTIONAL]
# - retry_delay_in_seconds(10): the delay in seconds to wait before retrying the job [OPTIONAL]
# - use_gcloud(True): whether to use the gcloud command or the google cloud run python operator [OPTIONAL]
# - sl_env_var: starlake variables specified as a map in json format - at least the root project path SL_ROOT should be specified [OPTIONAL]
# - run_dependencies_first(False): whereas the dependencies should be added and executed before each transformation that has to be performed within the dag (if not set, the dependencies will not be added) [OPTIONAL]
# - tags: a list of tags to be applied to the dag [OPTIONAL]
# Naming rule: scheduled or sensor, global or domain or table, cloudrun or bash or dataproc or serverless with free-text
# - catchup(False): whether to catch up the missed runs or not [OPTIONAL]
# - start_date: the start date of the dag (eg. 2022-01-01) [OPTIONAL]
# - end_date: the end date of the dag (eg. 2024-12-31) [OPTIONAL]
# - retries(1): the number of retries to attempt before failing the task [OPTIONAL]
# - retry_delay(300): the delay between retries in seconds [OPTIONAL]
# - default_dag_args: the default dag arguments specified as a map in json format [OPTIONAL]
# - data_cycle_enabled(False): whether the data cycle feature is enabled or not [OPTIONAL]
# - data_cycle: the data cycle to be used for the dag [OPTIONAL]
# - beyond_data_cycle_enabled(True): whether the beyond data cycle feature is enabled or not [OPTIONAL]
# - optional_dataset_enabled(False): whether a dataset can be treated as optional [OPTIONAL]
# - dataset_triggering_strategy(any): the dataset triggering strategy to be used for the non scheduled dag, one of any or all (if not set the default 'any' strategy will be used) [OPTIONAL]
# - min_timedelta_between_runs(900): the minimum timedelta between runs in seconds (900 by default) to avoid multiple dag executions when the strategy for dataset triggering is 'any' [OPTIONAL]
{% include 'templates/dags/__starlake_airflow_orchestrator.py' %}
{% include 'templates/dags/__starlake_cloud_run_execution.py' %}
{% include 'templates/dags/transform/__scheduled_task_tpl.py.j2' %}
