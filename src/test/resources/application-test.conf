include required("reference.conf")

# NOTE: this file should contain deviations from the standard ("production default") reference.conf for use
# in the Test context
# Typelevel Config loads application-test.conf first and if it doesn't find it, reference.conf
# Our own TypeHelper will look for application-test.conf first.

extraListeners = com.hortonworks.spark.atlas.SparkAtlasEventTracker
sql.queryExecutionListeners = com.hortonworks.spark.atlas.SparkAtlasEventTracker

archive = true

file-system = "file://"

sink-to-file=true

hive = false

grouped = true

analyze = false

assertions.active = true

connections {
  test-h2 {
    engine = "h2"

    ## The default URI is in memory only
    options {
        "url": "jdbc:h2:mem:test-"${COMET_TEST_ID}";DB_CLOSE_DELAY=-1"
        ## uncomment this in order to have traces (on the console) about the in-flight SQL
        # "url": "jdbc:h2:mem:test-"${COMET_TEST_ID}";DB_CLOSE_DELAY=-1;TRACE_LEVEL_SYSTEM_OUT=2",
        ## Uncomment the following to keep an on-disk trace of your test database:
        # "url":"jdbc:h2:/tmp/h2-"${COMET_TEST_ID}"",
        "driver": "org.h2.Driver"
        "user":"sa"
        "password":"sa"
    }
  }
}

audit {
  sink {
    type = "NoneSink" // By default
    connection = "test-h2"
    # bq-dataset = "audit"
  }
}

metrics {
  active = true
  sink {
    type = "NoneSink" // By default
    connection = "test-h2"
    # bq-dataset = "audit"
  }
}

spark {
  debug.maxToStringFields=100
  master = "local[*]"
}

elasticsearch {
  active = true
}
