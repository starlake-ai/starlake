"use strict";(self.webpackChunkstarlake=self.webpackChunkstarlake||[]).push([[8470],{3905:(e,t,a)=>{a.d(t,{Zo:()=>m,kt:()=>u});var n=a(67294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function l(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?l(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):l(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function o(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},l=Object.keys(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var p=n.createContext({}),d=function(e){var t=n.useContext(p),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},m=function(e){var t=d(e.components);return n.createElement(p.Provider,{value:t},e.children)},s="mdxType",k={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},c=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,l=e.originalType,p=e.parentName,m=o(e,["components","mdxType","originalType","parentName"]),s=d(a),c=r,u=s["".concat(p,".").concat(c)]||s[c]||k[c]||l;return a?n.createElement(u,i(i({ref:t},m),{},{components:a})):n.createElement(u,i({ref:t},m))}));function u(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var l=a.length,i=new Array(l);i[0]=c;var o={};for(var p in t)hasOwnProperty.call(t,p)&&(o[p]=t[p]);o.originalType=e,o[s]="string"==typeof e?e:r,i[1]=o;for(var d=2;d<l;d++)i[d]=a[d];return n.createElement.apply(null,i)}return n.createElement.apply(null,a)}c.displayName="MDXCreateElement"},16334:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>p,contentTitle:()=>i,default:()=>k,frontMatter:()=>l,metadata:()=>o,toc:()=>d});var n=a(87462),r=(a(67294),a(3905));const l={sidebar_position:200,title:"kafkaload"},i=void 0,o={unversionedId:"cli/kafkaload",id:"version-1.2.0/cli/kafkaload",title:"kafkaload",description:"Synopsis",source:"@site/versioned_docs/version-1.2.0/0800-cli/kafkaload.md",sourceDirName:"0800-cli",slug:"/cli/kafkaload",permalink:"/starlake/docs/cli/kafkaload",draft:!1,editUrl:"https://github.com/starlake-ai/starlake/edit/master/docs/versioned_docs/version-1.2.0/0800-cli/kafkaload.md",tags:[],version:"1.2.0",sidebarPosition:200,frontMatter:{sidebar_position:200,title:"kafkaload"},sidebar:"starlakeSidebar",previous:{title:"ingest",permalink:"/starlake/docs/cli/ingest"},next:{title:"lineage",permalink:"/starlake/docs/cli/lineage"}},p={},d=[{value:"Synopsis",id:"synopsis",level:2},{value:"Description",id:"description",level:2},{value:"Batch mode",id:"batch-mode",level:3},{value:"Streaming mode",id:"streaming-mode",level:3},{value:"Parameters",id:"parameters",level:2},{value:"Samples",id:"samples",level:2},{value:"Batch offload topic from kafka to a file",id:"batch-offload-topic-from-kafka-to-a-file",level:3}],m={toc:d},s="wrapper";function k(e){let{components:t,...l}=e;return(0,r.kt)(s,(0,n.Z)({},m,l,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h2",{id:"synopsis"},"Synopsis"),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"starlake kafkaload ","[options]")),(0,r.kt)("h2",{id:"description"},"Description"),(0,r.kt)("p",null,"Two modes are available : The batch mode and the streaming mode."),(0,r.kt)("h3",{id:"batch-mode"},"Batch mode"),(0,r.kt)("p",null,"In batch mode, you start the kafka (off)loader regurarly and the last consumed offset\nwill be stored in the ",(0,r.kt)("inlineCode",{parentName:"p"},"comet_offsets")," topic config\n(see ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/starlake-ai/starlake/blob/master/src/main/resources/reference-kafka.conf#L22"},"reference-kafka.conf")," for an example)."),(0,r.kt)("p",null,"When offloading data from kafka to a file, you may ask to coalesce the result to a specific number of files / partitions.\nIf you ask to coalesce to a single partition, the offloader will store the data in the exact filename you provided in the path\nargument."),(0,r.kt)("p",null,"The figure below describes the batch offloading process\n",(0,r.kt)("img",{src:a(53218).Z,width:"669",height:"504"})),(0,r.kt)("p",null,"The figure below describes the batch offloading process with ",(0,r.kt)("inlineCode",{parentName:"p"},'comet-offsets-mode = "FILE"'),"\n",(0,r.kt)("img",{src:a(83729).Z,width:"769",height:"521"})),(0,r.kt)("h3",{id:"streaming-mode"},"Streaming mode"),(0,r.kt)("p",null,"In this mode, te program keep running and you the comet_offsets topic is not used. The (off)loader will use a consumer group id\nyou specify in the access options of the topic configuration you are dealing with."),(0,r.kt)("h2",{id:"parameters"},"Parameters"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Parameter"),(0,r.kt)("th",{parentName:"tr",align:null},"Cardinality"),(0,r.kt)("th",{parentName:"tr",align:null},"Description"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"--config:",(0,r.kt)("inlineCode",{parentName:"td"},"<value>")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("em",{parentName:"td"},"Optional")),(0,r.kt)("td",{parentName:"tr",align:null},"Topic Name declared in reference.conf file")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"--connectionRef:",(0,r.kt)("inlineCode",{parentName:"td"},"<value>")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("em",{parentName:"td"},"Optional")),(0,r.kt)("td",{parentName:"tr",align:null},"Connection to any specific sink")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"--format:",(0,r.kt)("inlineCode",{parentName:"td"},"<value>")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("em",{parentName:"td"},"Optional")),(0,r.kt)("td",{parentName:"tr",align:null},"Read/Write format eq : parquet, json, csv ... Default to parquet.")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"--path:",(0,r.kt)("inlineCode",{parentName:"td"},"<value>")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("em",{parentName:"td"},"Optional")),(0,r.kt)("td",{parentName:"tr",align:null},"Source file for load and target file for store")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"--options:",(0,r.kt)("inlineCode",{parentName:"td"},"<value>")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("em",{parentName:"td"},"Optional")),(0,r.kt)("td",{parentName:"tr",align:null},"Options to pass to Spark Reader")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"--write-config:",(0,r.kt)("inlineCode",{parentName:"td"},"<value>")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("em",{parentName:"td"},"Optional")),(0,r.kt)("td",{parentName:"tr",align:null},"Topic Name declared in reference.conf file")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"--write-path:",(0,r.kt)("inlineCode",{parentName:"td"},"<value>")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("em",{parentName:"td"},"Optional")),(0,r.kt)("td",{parentName:"tr",align:null},"Source file for load and target file for store")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"--write-mode:",(0,r.kt)("inlineCode",{parentName:"td"},"<value>")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("em",{parentName:"td"},"Optional")),(0,r.kt)("td",{parentName:"tr",align:null},"When offload is true, describes how data should be stored on disk. Ignored if offload is false.")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"--write-options:",(0,r.kt)("inlineCode",{parentName:"td"},"<value>")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("em",{parentName:"td"},"Optional")),(0,r.kt)("td",{parentName:"tr",align:null},"Options to pass to Spark Writer")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"--write-format:",(0,r.kt)("inlineCode",{parentName:"td"},"<value>")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("em",{parentName:"td"},"Optional")),(0,r.kt)("td",{parentName:"tr",align:null},"Streaming format eq. kafka, console ...")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"--write-coalesce:",(0,r.kt)("inlineCode",{parentName:"td"},"<value>")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("em",{parentName:"td"},"Optional")),(0,r.kt)("td",{parentName:"tr",align:null},"Should we coalesce the resulting dataframe")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"--transform:",(0,r.kt)("inlineCode",{parentName:"td"},"<value>")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("em",{parentName:"td"},"Optional")),(0,r.kt)("td",{parentName:"tr",align:null},"Any transformation to apply to message before loading / offloading it")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"--stream:",(0,r.kt)("inlineCode",{parentName:"td"},"<value>")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("em",{parentName:"td"},"Optional")),(0,r.kt)("td",{parentName:"tr",align:null},"Should we use streaming mode ?")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"--streaming-trigger:",(0,r.kt)("inlineCode",{parentName:"td"},"<value>")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("em",{parentName:"td"},"Optional")),(0,r.kt)("td",{parentName:"tr",align:null},"Once / Continuous / ProcessingTime")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"--streaming-trigger-option:",(0,r.kt)("inlineCode",{parentName:"td"},"<value>")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("em",{parentName:"td"},"Optional")),(0,r.kt)("td",{parentName:"tr",align:null},"10 seconds for example. see ",(0,r.kt)("a",{parentName:"td",href:"https://spark.apache.org/docs/latest/api/java/org/apache/spark/sql/streaming/Trigger.html#ProcessingTime-java.lang.String-"},"https://spark.apache.org/docs/latest/api/java/org/apache/spark/sql/streaming/Trigger.html#ProcessingTime-java.lang.String-"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"--streaming-to-table:",(0,r.kt)("inlineCode",{parentName:"td"},"<value>")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("em",{parentName:"td"},"Optional")),(0,r.kt)("td",{parentName:"tr",align:null},"Table name to sink to")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"--streaming-partition-by:",(0,r.kt)("inlineCode",{parentName:"td"},"<value>")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("em",{parentName:"td"},"Optional")),(0,r.kt)("td",{parentName:"tr",align:null},"List of columns to use for partitioning")))),(0,r.kt)("h2",{id:"samples"},"Samples"),(0,r.kt)("h3",{id:"batch-offload-topic-from-kafka-to-a-file"},"Batch offload topic from kafka to a file"),(0,r.kt)("p",null,"Assume we want to periodically offload an avro topic to the disk and create a filename with the date time, the batch was started.\nWe need to provide the following input parameters to the starlake batch:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"offload: We set it to true since we are consuming data from kafka"),(0,r.kt)("li",{parentName:"ul"},"mode: Overwrite since we are creating a unique file for each starlake batch"),(0,r.kt)("li",{parentName:"ul"},"path: the file path where the consumed data will be stored. We can use here any standard starlake variable, for example ",(0,r.kt)("inlineCode",{parentName:"li"},"/tmp/file-{{sl_datetime}}.txt")),(0,r.kt)("li",{parentName:"ul"},"format: We may save it in any spark supported format (parquet, text, json ...)"),(0,r.kt)("li",{parentName:"ul"},"coalesce: Write all consumed messages into a single file if set to 1"),(0,r.kt)("li",{parentName:"ul"},"config: The config entry on the application.conf describing the topic connections options. See below.")))}k.isMDXComponent=!0},83729:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/kafka-offload-fs-1b2743b81e76d7adc87e0195e2f8b4b4.png"},53218:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/kafka-offload-f33e7634d7aa0e5a6038e74902d5edc7.png"}}]);