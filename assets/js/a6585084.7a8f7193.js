"use strict";(self.webpackChunkstarlake=self.webpackChunkstarlake||[]).push([[5046],{15680:(e,a,t)=>{t.d(a,{xA:()=>m,yg:()=>y});var n=t(96540);function r(e,a,t){return a in e?Object.defineProperty(e,a,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[a]=t,e}function o(e,a){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);a&&(n=n.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),t.push.apply(t,n)}return t}function i(e){for(var a=1;a<arguments.length;a++){var t=null!=arguments[a]?arguments[a]:{};a%2?o(Object(t),!0).forEach((function(a){r(e,a,t[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(t,a))}))}return e}function l(e,a){if(null==e)return{};var t,n,r=function(e,a){if(null==e)return{};var t,n,r={},o=Object.keys(e);for(n=0;n<o.length;n++)t=o[n],a.indexOf(t)>=0||(r[t]=e[t]);return r}(e,a);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)t=o[n],a.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var s=n.createContext({}),u=function(e){var a=n.useContext(s),t=a;return e&&(t="function"==typeof e?e(a):i(i({},a),e)),t},m=function(e){var a=u(e.components);return n.createElement(s.Provider,{value:a},e.children)},d="mdxType",c={inlineCode:"code",wrapper:function(e){var a=e.children;return n.createElement(n.Fragment,{},a)}},p=n.forwardRef((function(e,a){var t=e.components,r=e.mdxType,o=e.originalType,s=e.parentName,m=l(e,["components","mdxType","originalType","parentName"]),d=u(t),p=r,y=d["".concat(s,".").concat(p)]||d[p]||c[p]||o;return t?n.createElement(y,i(i({ref:a},m),{},{components:t})):n.createElement(y,i({ref:a},m))}));function y(e,a){var t=arguments,r=a&&a.mdxType;if("string"==typeof e||r){var o=t.length,i=new Array(o);i[0]=p;var l={};for(var s in a)hasOwnProperty.call(a,s)&&(l[s]=a[s]);l.originalType=e,l[d]="string"==typeof e?e:r,i[1]=l;for(var u=2;u<o;u++)i[u]=t[u];return n.createElement.apply(null,i)}return n.createElement.apply(null,t)}p.displayName="MDXCreateElement"},19365:(e,a,t)=>{t.d(a,{A:()=>i});var n=t(96540),r=t(20053);const o={tabItem:"tabItem_Ymn6"};function i(e){let{children:a,hidden:t,className:i}=e;return n.createElement("div",{role:"tabpanel",className:(0,r.A)(o.tabItem,i),hidden:t},a)}},11470:(e,a,t)=>{t.d(a,{A:()=>N});var n=t(9668),r=t(96540),o=t(20053),i=t(23104),l=t(56347),s=t(57485),u=t(31682),m=t(89466);function d(e){return function(e){return r.Children.map(e,(e=>{if(!e||(0,r.isValidElement)(e)&&function(e){const{props:a}=e;return!!a&&"object"==typeof a&&"value"in a}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}(e).map((e=>{let{props:{value:a,label:t,attributes:n,default:r}}=e;return{value:a,label:t,attributes:n,default:r}}))}function c(e){const{values:a,children:t}=e;return(0,r.useMemo)((()=>{const e=a??d(t);return function(e){const a=(0,u.X)(e,((e,a)=>e.value===a.value));if(a.length>0)throw new Error(`Docusaurus error: Duplicate values "${a.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[a,t])}function p(e){let{value:a,tabValues:t}=e;return t.some((e=>e.value===a))}function y(e){let{queryString:a=!1,groupId:t}=e;const n=(0,l.W6)(),o=function(e){let{queryString:a=!1,groupId:t}=e;if("string"==typeof a)return a;if(!1===a)return null;if(!0===a&&!t)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return t??null}({queryString:a,groupId:t});return[(0,s.aZ)(o),(0,r.useCallback)((e=>{if(!o)return;const a=new URLSearchParams(n.location.search);a.set(o,e),n.replace({...n.location,search:a.toString()})}),[o,n])]}function f(e){const{defaultValue:a,queryString:t=!1,groupId:n}=e,o=c(e),[i,l]=(0,r.useState)((()=>function(e){let{defaultValue:a,tabValues:t}=e;if(0===t.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(a){if(!p({value:a,tabValues:t}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${a}" but none of its children has the corresponding value. Available values are: ${t.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return a}const n=t.find((e=>e.default))??t[0];if(!n)throw new Error("Unexpected error: 0 tabValues");return n.value}({defaultValue:a,tabValues:o}))),[s,u]=y({queryString:t,groupId:n}),[d,f]=function(e){let{groupId:a}=e;const t=function(e){return e?`docusaurus.tab.${e}`:null}(a),[n,o]=(0,m.Dv)(t);return[n,(0,r.useCallback)((e=>{t&&o.set(e)}),[t,o])]}({groupId:n}),g=(()=>{const e=s??d;return p({value:e,tabValues:o})?e:null})();(0,r.useLayoutEffect)((()=>{g&&l(g)}),[g]);return{selectedValue:i,selectValue:(0,r.useCallback)((e=>{if(!p({value:e,tabValues:o}))throw new Error(`Can't select invalid tab value=${e}`);l(e),u(e),f(e)}),[u,f,o]),tabValues:o}}var g=t(92303);const h={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};function b(e){let{className:a,block:t,selectedValue:l,selectValue:s,tabValues:u}=e;const m=[],{blockElementScrollPositionUntilNextRender:d}=(0,i.a_)(),c=e=>{const a=e.currentTarget,t=m.indexOf(a),n=u[t].value;n!==l&&(d(a),s(n))},p=e=>{let a=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const t=m.indexOf(e.currentTarget)+1;a=m[t]??m[0];break}case"ArrowLeft":{const t=m.indexOf(e.currentTarget)-1;a=m[t]??m[m.length-1];break}}a?.focus()};return r.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,o.A)("tabs",{"tabs--block":t},a)},u.map((e=>{let{value:a,label:t,attributes:i}=e;return r.createElement("li",(0,n.A)({role:"tab",tabIndex:l===a?0:-1,"aria-selected":l===a,key:a,ref:e=>m.push(e),onKeyDown:p,onClick:c},i,{className:(0,o.A)("tabs__item",h.tabItem,i?.className,{"tabs__item--active":l===a})}),t??a)})))}function v(e){let{lazy:a,children:t,selectedValue:n}=e;const o=(Array.isArray(t)?t:[t]).filter(Boolean);if(a){const e=o.find((e=>e.props.value===n));return e?(0,r.cloneElement)(e,{className:"margin-top--md"}):null}return r.createElement("div",{className:"margin-top--md"},o.map(((e,a)=>(0,r.cloneElement)(e,{key:a,hidden:e.props.value!==n}))))}function w(e){const a=f(e);return r.createElement("div",{className:(0,o.A)("tabs-container",h.tabList)},r.createElement(b,(0,n.A)({},e,a)),r.createElement(v,(0,n.A)({},e,a)))}function N(e){const a=(0,g.A)();return r.createElement(w,(0,n.A)({key:String(a)},e))}},22195:(e,a,t)=>{t.r(a),t.d(a,{assets:()=>s,contentTitle:()=>i,default:()=>c,frontMatter:()=>o,metadata:()=>l,toc:()=>u});var n=t(9668),r=(t(96540),t(15680));t(11470),t(19365);const o={},i="General",l={unversionedId:"concepts/general",id:"version-1.1.0/concepts/general",title:"General",description:"Starlake is based on a YAML DSL (Domain Specific Language) to define your Extract, Load and Transform data pipelines. All these files are stored in the metadata folder.",source:"@site/versioned_docs/version-1.1.0/0100-concepts/010.general.mdx",sourceDirName:"0100-concepts",slug:"/concepts/general",permalink:"/starlake/docs/1.1.0/concepts/general",draft:!1,editUrl:"https://github.com/starlake-ai/starlake/edit/master/docs/versioned_docs/version-1.1.0/0100-concepts/010.general.mdx",tags:[],version:"1.1.0",sidebarPosition:10,frontMatter:{},sidebar:"starlakeSidebar",previous:{title:"How is Starlake different ?",permalink:"/starlake/docs/1.1.0/concepts/unique"},next:{title:"Extract",permalink:"/starlake/docs/1.1.0/concepts/extract"}},s={},u=[{value:"Metadata",id:"metadata",level:2},{value:"Domains",id:"domains",level:2},{value:"Tables",id:"tables",level:2},{value:"Connections",id:"connections",level:2},{value:"Environments",id:"environments",level:2},{value:"Refs",id:"refs",level:2}],m={toc:u},d="wrapper";function c(e){let{components:a,...t}=e;return(0,r.yg)(d,(0,n.A)({},m,t,{components:a,mdxType:"MDXLayout"}),(0,r.yg)("h1",{id:"general"},"General"),(0,r.yg)("p",null,"Starlake is based on a YAML DSL (Domain Specific Language) to define your ",(0,r.yg)("inlineCode",{parentName:"p"},"Extract"),", ",(0,r.yg)("inlineCode",{parentName:"p"},"Load")," and ",(0,r.yg)("inlineCode",{parentName:"p"},"Transform")," data pipelines. All these files are stored in the ",(0,r.yg)("inlineCode",{parentName:"p"},"metadata")," folder."),(0,r.yg)("h2",{id:"metadata"},"Metadata"),(0,r.yg)("p",null,"All the information related to a project is stored in the metadata folder. This folder is organized as follows:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("p",{parentName:"li"},(0,r.yg)("strong",{parentName:"p"},"metadata/extract"),": this directory contains all the extraction rules such as which tables and columns need to be extracted from an existing database.")),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("p",{parentName:"li"},(0,r.yg)("strong",{parentName:"p"},"metadata/load"),": this directory contains all the information related to load jobs. A load job is a job that load files from disk,\nvalidate the input records and store them in the target datawarehouse")),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("p",{parentName:"li"},(0,r.yg)("strong",{parentName:"p"},"metadata/transform"),": this directory contains all the information related to transform jobs.\nA transform job is a job that run against existing tables on the target database and write the result in a target table.\nThese are usually jobs that compute KPIs by aggregating values from different fact tables and or apply specific transformations to do some cleaning.")),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("p",{parentName:"li"},(0,r.yg)("strong",{parentName:"p"},"metadata/types"),": this is a companion directory to the metadata/load directory.\nIt contains all the custom types validation you wish to apply on the records loaded from a file.\nWe may require a record column to have a specific length or to verify a specific pattern like an email for example.\nThis allows to go much further than simply checking the input against standard python or java types.")),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("p",{parentName:"li"},(0,r.yg)("strong",{parentName:"p"},"metadata/expectations"),": This directory contains a library of expectations we may want to use in our project.\nExpectations are used to validate the data we load into our datawarehouse.\nFor example, we may want to check that the number of records loaded in a table is greater than 0.")),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("p",{parentName:"li"},(0,r.yg)("strong",{parentName:"p"},"metadata/connections.sl.yml"),": This file contains all the connections to our datawarehouse, although usually we just have one connection.")),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("p",{parentName:"li"},(0,r.yg)("strong",{parentName:"p"},"metadata/refs.sl.yml"),": In your SQL transforms, we may be joining tables coming from different domains or databases.\nIn that case, we normally need to reference our tables by their full names such as: ",(0,r.yg)("inlineCode",{parentName:"p"},"project-id.domain.my-table"),".\nThe refs file allows us to make our query more readable by allowing to map the name ",(0,r.yg)("inlineCode",{parentName:"p"},"my-table")," to its full name.")),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("p",{parentName:"li"},(0,r.yg)("strong",{parentName:"p"},"metadata/env.{{SL_ENV}}.sl.yml"),": we may use any of the variables defined in the env files in your extract, load and transforms jobs.\nThe SL_ENV env var activates a specific env file making it possible to assign to variables, values based on the active environment."))),(0,r.yg)("h2",{id:"domains"},"Domains"),(0,r.yg)("p",null,"Whether we load files or apply operations on tables, our load and transform jobs will end up writing to a table hosted in a domain."),(0,r.yg)("p",null,"A domain is a synonym to:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},"a schema in some databases such as Postgres or Snowflake"),(0,r.yg)("li",{parentName:"ul"},"a database in Databricks"),(0,r.yg)("li",{parentName:"ul"},"A dataset in BigQuery.")),(0,r.yg)("p",null,"Since tables are necessarily hosted in a domain, Starlake need to create a domain if it does not exist before it stores the data into the table.\nThe domain name is specified by the folder name where the table is defined.\nFor example, if we have a table defined in the following path: ",(0,r.yg)("inlineCode",{parentName:"p"},"metadata/transform/my-domain/my-table.sl.yml"),", then the domain name will be ",(0,r.yg)("inlineCode",{parentName:"p"},"my-domain"),"."),(0,r.yg)("admonition",{type:"note"},(0,r.yg)("p",{parentName:"admonition"},"We may still overload the domain name in the file ",(0,r.yg)("inlineCode",{parentName:"p"},"metadata/transform/my-domain/_config.sl.yml")," by specifying a different domain name in the ",(0,r.yg)("inlineCode",{parentName:"p"},"name")," property.")),(0,r.yg)("h2",{id:"tables"},"Tables"),(0,r.yg)("p",null,"Any load or transform job that will end up writing to a table ",(0,r.yg)("inlineCode",{parentName:"p"},"my-table")," in the domain ",(0,r.yg)("inlineCode",{parentName:"p"},"my-domain"),"\nis defined in the file ",(0,r.yg)("inlineCode",{parentName:"p"},"metadata/load/my-domain/my-table.sl.yml")," for load jobs and in the file ",(0,r.yg)("inlineCode",{parentName:"p"},"metadata/transform/my-domain/my-table.sl.yml")," for transform jobs."),(0,r.yg)("admonition",{type:"note"},(0,r.yg)("p",{parentName:"admonition"},"We may still overload the table name in the file ",(0,r.yg)("inlineCode",{parentName:"p"},"my-table.sl.yml")," by specifying a different table name in the ",(0,r.yg)("inlineCode",{parentName:"p"},"name")," property.")),(0,r.yg)("h2",{id:"connections"},"Connections"),(0,r.yg)("p",null,"Connections are defined in the file ",(0,r.yg)("inlineCode",{parentName:"p"},"metadata/connections.sl.yml"),". This file contains a list of connections.\nEach connection has a name and a type."),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},"The type is the type of the database we want to connect to: JDBC, BigQuery, Databricks, Spark, Hive, Filesystem ect ..."),(0,r.yg)("li",{parentName:"ul"},"The name is the name we will use to reference the connection in our load and transform jobs.")),(0,r.yg)("h2",{id:"environments"},"Environments"),(0,r.yg)("p",null,"Environments are defined in the file ",(0,r.yg)("inlineCode",{parentName:"p"},"metadata/env.[SL_ENV].sl.yml"),". This file contains a list of variables.\nEach variable has a name and a value."),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},"The name is the name we will use to reference the variable in our jobs using the syntax ",(0,r.yg)("inlineCode",{parentName:"li"},"{{variable}}")," or ",(0,r.yg)("inlineCode",{parentName:"li"},"${variable}"),"."),(0,r.yg)("li",{parentName:"ul"},"The value is the value of the variable.")),(0,r.yg)("p",null,"We may assign a value to a variable based on the active environment.\nFor example, we may want to use a different database name based on the environment we are running our job in.\nThe file ",(0,r.yg)("inlineCode",{parentName:"p"},"metadata/env.sl.yml")," is always loaded then, if the SL_ENV variable is defined, the file metadata/env.","[SL_ENV]",".sl.yml is also loaded\nand values defined in this file will override the values defined in the file ",(0,r.yg)("inlineCode",{parentName:"p"},"metadata/env.sl.yml"),"."),(0,r.yg)("h2",{id:"refs"},"Refs"),(0,r.yg)("p",null,"Refs are used essentially in SQL transform jobs. They allow to reference a table by its name instead of its full name."),(0,r.yg)("p",null,"For example, if we have a table ",(0,r.yg)("inlineCode",{parentName:"p"},"my-table")," in the domain ",(0,r.yg)("inlineCode",{parentName:"p"},"my-domain"),", we may reference it in our SQL query by using the syntax ",(0,r.yg)("inlineCode",{parentName:"p"},"my-table")," instead of ",(0,r.yg)("inlineCode",{parentName:"p"},"my-domain.my-table")," or ",(0,r.yg)("inlineCode",{parentName:"p"},"my-database.my-domain.my-table"),"."),(0,r.yg)("p",null,"Refs are also useful to implicitly reference a table in a different domain or database based on the environment our job is running in: DEV or PROD for example."))}c.isMDXComponent=!0}}]);