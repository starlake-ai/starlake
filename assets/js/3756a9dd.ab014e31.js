"use strict";(self.webpackChunkstarlake=self.webpackChunkstarlake||[]).push([[8642],{15680:(e,n,t)=>{t.d(n,{xA:()=>m,yg:()=>y});var r=t(96540);function a(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function o(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);n&&(r=r.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,r)}return t}function s(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?o(Object(t),!0).forEach((function(n){a(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function i(e,n){if(null==e)return{};var t,r,a=function(e,n){if(null==e)return{};var t,r,a={},o=Object.keys(e);for(r=0;r<o.length;r++)t=o[r],n.indexOf(t)>=0||(a[t]=e[t]);return a}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)t=o[r],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(a[t]=e[t])}return a}var p=r.createContext({}),l=function(e){var n=r.useContext(p),t=n;return e&&(t="function"==typeof e?e(n):s(s({},n),e)),t},m=function(e){var n=l(e.components);return r.createElement(p.Provider,{value:n},e.children)},u="mdxType",c={inlineCode:"code",wrapper:function(e){var n=e.children;return r.createElement(r.Fragment,{},n)}},f=r.forwardRef((function(e,n){var t=e.components,a=e.mdxType,o=e.originalType,p=e.parentName,m=i(e,["components","mdxType","originalType","parentName"]),u=l(t),f=a,y=u["".concat(p,".").concat(f)]||u[f]||c[f]||o;return t?r.createElement(y,s(s({ref:n},m),{},{components:t})):r.createElement(y,s({ref:n},m))}));function y(e,n){var t=arguments,a=n&&n.mdxType;if("string"==typeof e||a){var o=t.length,s=new Array(o);s[0]=f;var i={};for(var p in n)hasOwnProperty.call(n,p)&&(i[p]=n[p]);i.originalType=e,i[u]="string"==typeof e?e:a,s[1]=i;for(var l=2;l<o;l++)s[l]=t[l];return r.createElement.apply(null,s)}return r.createElement.apply(null,t)}f.displayName="MDXCreateElement"},83631:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>p,contentTitle:()=>s,default:()=>c,frontMatter:()=>o,metadata:()=>i,toc:()=>l});var r=t(9668),a=(t(96540),t(15680));const o={},s="Python Transforms",i={unversionedId:"guides/transform/python",id:"guides/transform/python",title:"Python Transforms",description:"In addition to SQL transforms, you may run Python transforms in your pipeline.",source:"@site/docs/0300-guides/300-transform/120-python.mdx",sourceDirName:"0300-guides/300-transform",slug:"/guides/transform/python",permalink:"/starlake/docs/next/guides/transform/python",draft:!1,editUrl:"https://github.com/starlake-ai/starlake/edit/master/docs/docs/0300-guides/300-transform/120-python.mdx",tags:[],version:"current",sidebarPosition:120,frontMatter:{},sidebar:"starlakeSidebar",previous:{title:"SQL Transforms",permalink:"/starlake/docs/next/guides/transform/sql"},next:{title:"Export",permalink:"/starlake/docs/next/guides/transform/export"}},p={},l=[],m={toc:l},u="wrapper";function c(e){let{components:n,...t}=e;return(0,a.yg)(u,(0,r.A)({},m,t,{components:n,mdxType:"MDXLayout"}),(0,a.yg)("h1",{id:"python-transforms"},"Python Transforms"),(0,a.yg)("p",null,"In addition to SQL transforms, you may run Python transforms in your pipeline.\nPython transforms are defined by a Python function that takes a DataFrame as input and returns a DataFrame as output.\nThe function is then registered as a transform in the pipeline."),(0,a.yg)("p",null,"Exactly like the SQL transform, you can define a python transform by creating a python file and adding it\nto the ",(0,a.yg)("inlineCode",{parentName:"p"},"metadata/transform/<domain>")," directory."),(0,a.yg)("p",null,"You can also define a YAML configuration file for the python script using the exact same format as the SQL transform."),(0,a.yg)("p",null,"Arguments specified in the command line through the ",(0,a.yg)("inlineCode",{parentName:"p"},"--options")," flag will be passed to the python function as keyword arguments:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-bash"},"\n$ starlake transform --name <domain>.<transform_name> --options key1=value1,key2=value2\n\n")),(0,a.yg)("p",null,"will be passed as keyword arguments to the python function:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-bash"},"\n<transform-name>.py --key1 value1 --key2 value2\n\n")),(0,a.yg)("p",null,"The dataframe returned by the python function will be saved as the output table of the transform."),(0,a.yg)("admonition",{type:"note"},(0,a.yg)("p",{parentName:"admonition"},"Before returning the dataframe, the function must create a temporary view with the name ",(0,a.yg)("inlineCode",{parentName:"p"},"SL_THIS")," so that the dataframe can be saved as a table.")),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-python"},'\nimport sys\nfrom random import random\nfrom operator import add\n\nfrom pyspark.sql import SparkSession\n\nif __name__ == "__main__":\n    """\n        Usage: pi [partitions]\n    """\n    spark = SparkSession \\\n        .builder \\\n        .getOrCreate()\n\n    partitions = 2\n    n = 100000 * partitions\n\n    def f(_: int) -> float:\n        x = random() * 2 - 1\n        y = random() * 2 - 1\n        return 1 if x ** 2 + y ** 2 <= 1 else 0\n\n    count = spark.sparkContext.parallelize(range(1, n + 1), partitions).map(f).reduce(add)\n    result = "Pi is roughly %f" % (4.0 * count / n)\n    df = spark.createDataFrame([[result]])\n    df.createOrReplaceTempView("SL_THIS")\n\n')))}c.isMDXComponent=!0}}]);