"use strict";(self.webpackChunkstarlake_docs=self.webpackChunkstarlake_docs||[]).push([[5265],{3905:(e,t,a)=>{a.d(t,{Zo:()=>m,kt:()=>u});var n=a(7294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function l(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?l(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):l(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function i(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},l=Object.keys(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var p=n.createContext({}),d=function(e){var t=n.useContext(p),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},m=function(e){var t=d(e.components);return n.createElement(p.Provider,{value:t},e.children)},s="mdxType",k={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},c=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,l=e.originalType,p=e.parentName,m=i(e,["components","mdxType","originalType","parentName"]),s=d(a),c=r,u=s["".concat(p,".").concat(c)]||s[c]||k[c]||l;return a?n.createElement(u,o(o({ref:t},m),{},{components:a})):n.createElement(u,o({ref:t},m))}));function u(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var l=a.length,o=new Array(l);o[0]=c;var i={};for(var p in t)hasOwnProperty.call(t,p)&&(i[p]=t[p]);i.originalType=e,i[s]="string"==typeof e?e:r,o[1]=i;for(var d=2;d<l;d++)o[d]=a[d];return n.createElement.apply(null,o)}return n.createElement.apply(null,a)}c.displayName="MDXCreateElement"},6340:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>p,contentTitle:()=>o,default:()=>k,frontMatter:()=>l,metadata:()=>i,toc:()=>d});var n=a(7462),r=(a(7294),a(3905));const l={sidebar_position:120,title:"kafkaload"},o=void 0,i={unversionedId:"cli/kafkaload",id:"version-0.8.0/cli/kafkaload",title:"kafkaload",description:"Synopsis",source:"@site/versioned_docs/version-0.8.0/cli/kafkaload.md",sourceDirName:"cli",slug:"/cli/kafkaload",permalink:"/starlake/docs/cli/kafkaload",draft:!1,editUrl:"https://github.com/starlake-ai/starlake/edit/master/docs/versioned_docs/version-0.8.0/cli/kafkaload.md",tags:[],version:"0.8.0",sidebarPosition:120,frontMatter:{sidebar_position:120,title:"kafkaload"},sidebar:"starlakeSidebar",previous:{title:"jobs2gv",permalink:"/starlake/docs/cli/jobs2gv"},next:{title:"load",permalink:"/starlake/docs/cli/load"}},p={},d=[{value:"Synopsis",id:"synopsis",level:2},{value:"Description",id:"description",level:2},{value:"Batch mode",id:"batch-mode",level:3},{value:"Streaming mode",id:"streaming-mode",level:3},{value:"Parameters",id:"parameters",level:2},{value:"Samples",id:"samples",level:2},{value:"Batch offload topic from kafka to a file",id:"batch-offload-topic-from-kafka-to-a-file",level:3}],m={toc:d},s="wrapper";function k(e){let{components:t,...l}=e;return(0,r.kt)(s,(0,n.Z)({},m,l,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h2",{id:"synopsis"},"Synopsis"),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"starlake kafkaload ","[options]")),(0,r.kt)("h2",{id:"description"},"Description"),(0,r.kt)("p",null,"Two modes are available : The batch mode and the streaming mode."),(0,r.kt)("h3",{id:"batch-mode"},"Batch mode"),(0,r.kt)("p",null,"In batch mode, you start the kafka (off)loader regurarly and the last consumed offset\nwill be stored in the ",(0,r.kt)("inlineCode",{parentName:"p"},"comet_offsets")," topic config\n(see ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/starlake-ai/starlake/blob/master/src/main/resources/reference-kafka.conf#L22"},"reference-kafka.conf")," for an example)."),(0,r.kt)("p",null,"When offloading data from kafka to a file, you may ask to coalesce the result to a specific number of files / partitions.\nIf you ask to coalesce to a single partition, the offloader will store the data in the exact filename you provided in the path\nargument."),(0,r.kt)("p",null,"The figure below describes the batch offloading process\n",(0,r.kt)("img",{src:a(3218).Z,width:"669",height:"504"})),(0,r.kt)("p",null,"The figure below describes the batch offloading process with ",(0,r.kt)("inlineCode",{parentName:"p"},'comet-offsets-mode = "FILE"'),"\n",(0,r.kt)("img",{src:a(3729).Z,width:"769",height:"521"})),(0,r.kt)("h3",{id:"streaming-mode"},"Streaming mode"),(0,r.kt)("p",null,"In this mode, te program keep running and you the comet_offsets topic is not used. The (off)loader will use a consumer group id\nyou specify in the access options of the topic configuration you are dealing with."),(0,r.kt)("h2",{id:"parameters"},"Parameters"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Parameter"),(0,r.kt)("th",{parentName:"tr",align:null},"Cardinality"),(0,r.kt)("th",{parentName:"tr",align:null},"Description"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"--config:",(0,r.kt)("inlineCode",{parentName:"td"},"<value>")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("em",{parentName:"td"},"Optional")),(0,r.kt)("td",{parentName:"tr",align:null},"Topic Name declared in reference.conf file")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"--connectionRef:",(0,r.kt)("inlineCode",{parentName:"td"},"<value>")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("em",{parentName:"td"},"Optional")),(0,r.kt)("td",{parentName:"tr",align:null},"Connection to any specific sink")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"--format:",(0,r.kt)("inlineCode",{parentName:"td"},"<value>")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("em",{parentName:"td"},"Optional")),(0,r.kt)("td",{parentName:"tr",align:null},"Read/Write format eq : parquet, json, csv ... Default to parquet.")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"--path:",(0,r.kt)("inlineCode",{parentName:"td"},"<value>")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("em",{parentName:"td"},"Optional")),(0,r.kt)("td",{parentName:"tr",align:null},"Source file for load and target file for store")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"--options:",(0,r.kt)("inlineCode",{parentName:"td"},"<value>")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("em",{parentName:"td"},"Optional")),(0,r.kt)("td",{parentName:"tr",align:null},"Options to pass to Spark Reader")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"--write-config:",(0,r.kt)("inlineCode",{parentName:"td"},"<value>")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("em",{parentName:"td"},"Optional")),(0,r.kt)("td",{parentName:"tr",align:null},"Topic Name declared in reference.conf file")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"--write-path:",(0,r.kt)("inlineCode",{parentName:"td"},"<value>")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("em",{parentName:"td"},"Optional")),(0,r.kt)("td",{parentName:"tr",align:null},"Source file for load and target file for store")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"--write-mode:",(0,r.kt)("inlineCode",{parentName:"td"},"<value>")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("em",{parentName:"td"},"Optional")),(0,r.kt)("td",{parentName:"tr",align:null},"When offload is true, describes how data should be stored on disk. Ignored if offload is false.")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"--write-options:",(0,r.kt)("inlineCode",{parentName:"td"},"<value>")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("em",{parentName:"td"},"Optional")),(0,r.kt)("td",{parentName:"tr",align:null},"Options to pass to Spark Writer")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"--write-format:",(0,r.kt)("inlineCode",{parentName:"td"},"<value>")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("em",{parentName:"td"},"Optional")),(0,r.kt)("td",{parentName:"tr",align:null},"Streaming format eq. kafka, console ...")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"--write-coalesce:",(0,r.kt)("inlineCode",{parentName:"td"},"<value>")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("em",{parentName:"td"},"Optional")),(0,r.kt)("td",{parentName:"tr",align:null},"Should we coalesce the resulting dataframe")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"--transform:",(0,r.kt)("inlineCode",{parentName:"td"},"<value>")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("em",{parentName:"td"},"Optional")),(0,r.kt)("td",{parentName:"tr",align:null},"Any transformation to apply to message before loading / offloading it")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"--stream:",(0,r.kt)("inlineCode",{parentName:"td"},"<value>")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("em",{parentName:"td"},"Optional")),(0,r.kt)("td",{parentName:"tr",align:null},"Should we use streaming mode ?")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"--streaming-trigger:",(0,r.kt)("inlineCode",{parentName:"td"},"<value>")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("em",{parentName:"td"},"Optional")),(0,r.kt)("td",{parentName:"tr",align:null},"Once / Continuous / ProcessingTime")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"--streaming-trigger-option:",(0,r.kt)("inlineCode",{parentName:"td"},"<value>")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("em",{parentName:"td"},"Optional")),(0,r.kt)("td",{parentName:"tr",align:null},"10 seconds for example. see ",(0,r.kt)("a",{parentName:"td",href:"https://spark.apache.org/docs/latest/api/java/org/apache/spark/sql/streaming/Trigger.html#ProcessingTime-java.lang.String-"},"https://spark.apache.org/docs/latest/api/java/org/apache/spark/sql/streaming/Trigger.html#ProcessingTime-java.lang.String-"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"--streaming-to-table:",(0,r.kt)("inlineCode",{parentName:"td"},"<value>")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("em",{parentName:"td"},"Optional")),(0,r.kt)("td",{parentName:"tr",align:null},"Table name to sink to")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"--streaming-partition-by:",(0,r.kt)("inlineCode",{parentName:"td"},"<value>")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("em",{parentName:"td"},"Optional")),(0,r.kt)("td",{parentName:"tr",align:null},"List of columns to use for partitioning")))),(0,r.kt)("h2",{id:"samples"},"Samples"),(0,r.kt)("h3",{id:"batch-offload-topic-from-kafka-to-a-file"},"Batch offload topic from kafka to a file"),(0,r.kt)("p",null,"Assume we want to periodically offload an avro topic to the disk and create a filename with the date time, the batch was started.\nWe need to provide the following input parameters to the starlake batch:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"offload: We set it to true since we are consuming data from kafka"),(0,r.kt)("li",{parentName:"ul"},"mode: Overwrite since we are creating a unique file for each starlake batch"),(0,r.kt)("li",{parentName:"ul"},"path: the file path where the consumed data will be stored. We can use here any standard starlake variable, for example ",(0,r.kt)("inlineCode",{parentName:"li"},"/tmp/file-{{comet_datetime}}.txt")),(0,r.kt)("li",{parentName:"ul"},"format: We may save it in any spark supported format (parquet, text, json ...)"),(0,r.kt)("li",{parentName:"ul"},"coalesce: Write all consumed messages into a single file if set to 1"),(0,r.kt)("li",{parentName:"ul"},"config: The config entry on the application.conf describing the topic connections options. See below.")))}k.isMDXComponent=!0},3729:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/kafka-offload-fs-1b2743b81e76d7adc87e0195e2f8b4b4.png"},3218:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/kafka-offload-f33e7634d7aa0e5a6038e74902d5edc7.png"}}]);