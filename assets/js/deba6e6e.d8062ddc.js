"use strict";(self.webpackChunkstarlake=self.webpackChunkstarlake||[]).push([[1805],{3905:(e,t,n)=>{n.d(t,{Zo:()=>m,kt:()=>d});var r=n(67294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function s(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},o=Object.keys(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var p=r.createContext({}),l=function(e){var t=r.useContext(p),n=t;return e&&(n="function"==typeof e?e(t):s(s({},t),e)),n},m=function(e){var t=l(e.components);return r.createElement(p.Provider,{value:t},e.children)},u="mdxType",f={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},c=r.forwardRef((function(e,t){var n=e.components,a=e.mdxType,o=e.originalType,p=e.parentName,m=i(e,["components","mdxType","originalType","parentName"]),u=l(n),c=a,d=u["".concat(p,".").concat(c)]||u[c]||f[c]||o;return n?r.createElement(d,s(s({ref:t},m),{},{components:n})):r.createElement(d,s({ref:t},m))}));function d(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var o=n.length,s=new Array(o);s[0]=c;var i={};for(var p in t)hasOwnProperty.call(t,p)&&(i[p]=t[p]);i.originalType=e,i[u]="string"==typeof e?e:a,s[1]=i;for(var l=2;l<o;l++)s[l]=n[l];return r.createElement.apply(null,s)}return r.createElement.apply(null,n)}c.displayName="MDXCreateElement"},4034:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>f,frontMatter:()=>o,metadata:()=>i,toc:()=>l});var r=n(87462),a=(n(67294),n(3905));const o={},s="Python Transforms",i={unversionedId:"guides/transform/python",id:"version-1.2.0/guides/transform/python",title:"Python Transforms",description:"In addition to SQL transforms, you may run Python transforms in your pipeline.",source:"@site/versioned_docs/version-1.2.0/0300-guides/300-transform/120-python.mdx",sourceDirName:"0300-guides/300-transform",slug:"/guides/transform/python",permalink:"/starlake/docs/guides/transform/python",draft:!1,editUrl:"https://github.com/starlake-ai/starlake/edit/master/docs/versioned_docs/version-1.2.0/0300-guides/300-transform/120-python.mdx",tags:[],version:"1.2.0",sidebarPosition:120,frontMatter:{},sidebar:"starlakeSidebar",previous:{title:"SQL Transforms",permalink:"/starlake/docs/guides/transform/sql"},next:{title:"Export",permalink:"/starlake/docs/guides/transform/export"}},p={},l=[],m={toc:l},u="wrapper";function f(e){let{components:t,...n}=e;return(0,a.kt)(u,(0,r.Z)({},m,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"python-transforms"},"Python Transforms"),(0,a.kt)("p",null,"In addition to SQL transforms, you may run Python transforms in your pipeline.\nPython transforms are defined by a Python function that takes a DataFrame as input and returns a DataFrame as output.\nThe function is then registered as a transform in the pipeline."),(0,a.kt)("p",null,"Exactly like the SQL transform, you can define a python transform by creating a python file and adding it\nto the ",(0,a.kt)("inlineCode",{parentName:"p"},"metadata/transform/<domain>")," directory."),(0,a.kt)("p",null,"You can also define a YAML configuration file for the python script using the exact same format as the SQL transform."),(0,a.kt)("p",null,"Arguments specified in the command line through the ",(0,a.kt)("inlineCode",{parentName:"p"},"--options")," flag will be passed to the python function as keyword arguments:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"\n$ starlake transform --name <domain>.<transform_name> --options key1=value1,key2=value2\n\n")),(0,a.kt)("p",null,"will be passed as keyword arguments to the python function:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"\n<transform-name>.py --key1 value1 --key2 value2\n\n")),(0,a.kt)("p",null,"The dataframe returned by the python function will be saved as the output table of the transform."),(0,a.kt)("admonition",{type:"note"},(0,a.kt)("p",{parentName:"admonition"},"Before returning the dataframe, the function must create a temporary view with the name ",(0,a.kt)("inlineCode",{parentName:"p"},"SL_THIS")," so that the dataframe can be saved as a table.")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'\nimport sys\nfrom random import random\nfrom operator import add\n\nfrom pyspark.sql import SparkSession\n\nif __name__ == "__main__":\n    """\n        Usage: pi [partitions]\n    """\n    spark = SparkSession \\\n        .builder \\\n        .getOrCreate()\n\n    partitions = 2\n    n = 100000 * partitions\n\n    def f(_: int) -> float:\n        x = random() * 2 - 1\n        y = random() * 2 - 1\n        return 1 if x ** 2 + y ** 2 <= 1 else 0\n\n    count = spark.sparkContext.parallelize(range(1, n + 1), partitions).map(f).reduce(add)\n    result = "Pi is roughly %f" % (4.0 * count / n)\n    df = spark.createDataFrame([[result]])\n    df.createOrReplaceTempView("SL_THIS")\n\n')))}f.isMDXComponent=!0}}]);