name: starlake
version: '3.8'

services:
  starlake-db:
    image: postgres:15.2-alpine
    restart: always
    container_name: starlake-db
    ports:
      - ${SL_DB_PORT:-5432}:5432
    environment:
      POSTGRES_USER: ${SL_POSTGRES_USER:-dbuser}
      POSTGRES_PASSWORD: ${SL_POSTGRES_PASSWORD:-dbuser123}
      POSTGRES_DB: ${SL_POSTGRES_DB:-starlake}
    volumes:
      - pgdata:/var/lib/postgresql/data

  starlake-nas:
    image: starlakeai/starlake-nas:latest
    build:
      context: .  # Assuming Dockerfile.nas is in the current directory
      dockerfile: Dockerfile_nas
    container_name: starlake-nas
    restart: on-failure
    privileged: true  # Required to access /proc/fs/nfsd
    ports:
      - ${SL_NFS_PORT:-2049}:2049  # NFS default port
    volumes:
      - projects_data:/projects

  starlake-init-airflow-db:
    image: starlakeai/starlake-airflow:latest
    build:
      context: .  # Assuming Dockerfile.airflow is in the current directory
      dockerfile: Dockerfile_airflow
    container_name: starlake-init-airflow-db
    depends_on:
      - starlake-db
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${SL_POSTGRES_USER:-dbuser}:${SL_POSTGRES_PASSWORD:-dbuser123}@starlake-db:5432/${SL_POSTGRES_DB:-starlake}
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
    entrypoint: >
      /bin/bash -c "
      sleep 10 &&
      airflow db upgrade &&
      airflow users create --username ${AIRFLOW_USERNAME:-admin} --firstname ${AIRFLOW_FIRSTNAME:-Admin} --lastname ${AIRFLOW_LASTNAME:-User} --role Admin --email ${AIRFLOW_EMAIL:-admin@example.com} --password ${AIRFLOW_PASSWORD:-admin}"

  starlake-airflow:
    image: starlakeai/starlake-airflow:latest
    build:
      context: .  # Assuming Dockerfile.airflow is in the current directory
      dockerfile: Dockerfile_airflow
    container_name: starlake-airflow
    restart: on-failure
    user: root
    depends_on:
      - starlake-db
      - starlake-nas
      - starlake-init-airflow-db
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${SL_POSTGRES_USER:-dbuser}:${SL_POSTGRES_PASSWORD:-dbuser123}@starlake-db:5432/${SL_POSTGRES_DB:-starlake}
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      SL_HOME: /app/starlake
    entrypoint: >
      /bin/bash -c "
      sleep 120 &&
      mount -v -o nolock starlake-nas:/projects/dags /opt/airflow/dags &&
      airflow scheduler &
      exec airflow webserver"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock  # Mount Docker socket to run Docker commands from the container
      - /etc/passwd:/etc/passwd:ro
      - /etc/group:/etc/group:ro
    ports:
      - ${SL_AIRFLOW_PORT:-8080}:8080  # Airflow Webserver port
    privileged: true  # Required for mounting NFS

  starlake-api:
    image: starlakeai/starlake-1.3-api:${SL_API_VERSION:-0.1}
    pull_policy: always
    container_name: starlake-api
    restart: on-failure
    depends_on:
      - starlake-db
      - starlake-nas
      - starlake-airflow
    privileged: true  # Required for mount permissions
    ports:
      - ${SL_API_HTTP_PORT:-9000}:9000  # starlake-api default port
    environment:
      - SL_HOME=/app/starlake
      - SL_FS=file://
      - SL_ENV=
      - SL_ROOT=
      - SL_USE_LOCAL_FILE_SYSTEM=false
      - SL_API_GIT_COMMAND_ROOT=/git
      - SL_API_SECURE=false
      - SL_API_SESSION_AS_HEADER=true
      - SL_API_HTTP_FRONT_URL=http://starlake-ui
      - SL_API_HTTP_INTERFACE=0.0.0.0
      - SL_API_HTTP_PORT=9000
      - SL_LOG_LEVEL=info
      - SL_API_JDBC_DRIVER=org.postgresql.Driver
      - SL_API_JDBC_USER=${SL_POSTGRES_USER:-dbuser}
      - SL_API_JDBC_PASSWORD=${SL_POSTGRES_PASSWORD:-dbuser123}
      - SL_API_JDBC_URL=jdbc:postgresql://starlake-db:5432/${SL_POSTGRES_DB:-starlake}?user=${SL_POSTGRES_USER:-dbuser}&password=${SL_POSTGRES_PASSWORD:-dbuser123} # JDBC URL to connect to the database
      - SL_API_DOMAIN=localhost
      - SL_API_PROJECT_ROOT=/mnt/filestore/projects
      - ENVIRONMENT=local # local environment
      - FILESTORE_SHARE_NAME=projects  # Environment variable to specify the share name of the NAS
      - FILESTORE_IP_ADDRESS=starlake-nas  # Environment variable to specify the IP address of the NAS
      - FILESTORE_MNT_DIR=/mnt/filestore/projects  # Environment variable to specify the mount path inside starlake-api container

  starlake-ui:
    image: starlakeai/starlake-1.3-ui:${SL_UI_VERSION:-0.1}
    pull_policy: always
    container_name: starlake-ui
    restart: on-failure
    depends_on:
      - starlake-api
    privileged: true  # Required for mount permissions
    ports:
      - ${SL_PORT:-80}:80  # starlake-ui default port
    environment:
      - FILESTORE_SHARE_NAME=projects  # Environment variable to specify the share name of the NAS
      - FILESTORE_IP_ADDRESS=starlake-nas  # Environment variable to specify the IP address of the NAS
      - FILESTORE_MNT_DIR=/mnt/filestore/projects  # Environment variable to specify the mount path inside starlake-api container
#    command: >
#      npm run start:prod
    volumes:
      - .env.docker:/app/.env:ro

volumes:
  projects_data:
#    driver: local
  pgdata:
#    driver: local
